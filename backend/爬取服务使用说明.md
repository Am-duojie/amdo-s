# 爬取服务使用说明

## ⚠️ 重要警告

**本爬取服务仅供学习研究使用，请勿用于商业用途！**

### 法律风险
1. **违反服务条款**：大多数网站的服务条款禁止爬取
2. **可能违法**：未经授权爬取可能违反《网络安全法》等相关法律
3. **IP封禁**：频繁爬取可能导致IP被封禁
4. **法律诉讼**：可能面临法律诉讼风险

### 道德考量
- 尊重网站的服务条款和robots.txt
- 不要对服务器造成过大负担
- 不要用于商业竞争

## 推荐方案

### ✅ 优先使用官方API
1. **联系平台商务部门**获取官方API
2. **申请开发者账号**使用官方接口
3. **签署合作协议**获得合法授权

### ✅ 使用公开数据源
- 使用官方提供的价格查询接口
- 使用开放数据API
- 使用授权的数据服务

## 技术实现（仅供学习）

### 1. 基本爬取流程

```python
from app.secondhand_app.scraper_service import scraper_service

# 爬取价格
price = scraper_service.estimate(
    device_type='手机',
    brand='苹果',
    model='iPhone 15 Pro Max',
    storage='256GB',
    condition='good'
)
```

### 2. 分析网站结构

#### 方法1：浏览器开发者工具
1. 打开目标网站
2. 按F12打开开发者工具
3. 查看Network标签页的网络请求
4. 查找API接口（通常返回JSON数据）

#### 方法2：查看页面源码
1. 右键页面 -> 查看页面源码
2. 查找价格相关的HTML元素
3. 使用BeautifulSoup解析

#### 方法3：使用Selenium（动态内容）
```python
from selenium import webdriver
from selenium.webdriver.common.by import By

driver = webdriver.Chrome()
driver.get('https://www.example.com')
price_element = driver.find_element(By.CLASS_NAME, 'price')
price = price_element.text
```

### 3. 反爬虫对策

#### 常见反爬虫机制
1. **User-Agent检测**：已设置常见浏览器UA
2. **IP限制**：使用代理IP池
3. **验证码**：需要OCR识别或人工处理
4. **JavaScript渲染**：使用Selenium或Playwright
5. **Cookie验证**：需要维护Session

#### 应对措施
```python
# 1. 使用代理
proxies = {
    'http': 'http://proxy.example.com:8080',
    'https': 'https://proxy.example.com:8080'
}
response = requests.get(url, proxies=proxies)

# 2. 使用Session保持Cookie
session = requests.Session()
session.get(url)  # 获取Cookie
response = session.get(target_url)  # 使用Cookie

# 3. 设置请求间隔
import time
time.sleep(2)  # 延迟2秒

# 4. 随机User-Agent
import random
user_agents = [
    'Mozilla/5.0 ...',
    'Mozilla/5.0 ...',
]
headers = {'User-Agent': random.choice(user_agents)}
```

## 实际案例分析

### 案例1：分析爱回收网站

1. **打开网站**：https://www.aihuishou.com
2. **搜索商品**：iPhone 15 Pro Max
3. **查看网络请求**：
   - 打开开发者工具 -> Network
   - 查找XHR/Fetch请求
   - 查找包含"price"或"estimate"的请求
4. **分析请求格式**：
   ```javascript
   // 可能的API请求
   POST /api/v1/estimate
   {
     "brand": "苹果",
     "model": "iPhone 15 Pro Max",
     "storage": "256GB"
   }
   ```
5. **模拟请求**：
   ```python
   response = requests.post(
       'https://www.aihuishou.com/api/v1/estimate',
       json={'brand': '苹果', 'model': 'iPhone 15 Pro Max', 'storage': '256GB'},
       headers={'User-Agent': '...'}
   )
   ```

### 案例2：使用Selenium处理动态内容

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

options = webdriver.ChromeOptions()
options.add_argument('--headless')  # 无头模式
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(options=options)
try:
    driver.get('https://www.example.com')
    # 等待价格元素加载
    price_element = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, 'price'))
    )
    price = price_element.text
finally:
    driver.quit()
```

## 最佳实践

### 1. 遵守robots.txt
```python
from urllib.robotparser import RobotFileParser

rp = RobotFileParser()
rp.set_url('https://www.example.com/robots.txt')
rp.read()
if rp.can_fetch('*', '/search'):
    # 允许爬取
    pass
```

### 2. 设置合理的请求频率
```python
import time
from datetime import datetime

class RateLimiter:
    def __init__(self, max_requests=10, time_window=60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = []
    
    def wait_if_needed(self):
        now = datetime.now()
        # 移除过期请求
        self.requests = [r for r in self.requests 
                        if (now - r).seconds < self.time_window]
        
        if len(self.requests) >= self.max_requests:
            sleep_time = self.time_window - (now - self.requests[0]).seconds
            time.sleep(sleep_time)
        
        self.requests.append(now)
```

### 3. 错误处理和重试
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def scrape_with_retry(url):
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    return response
```

### 4. 数据验证
```python
def validate_price(price):
    """验证价格合理性"""
    if not isinstance(price, (int, float)):
        return False
    if price < 0 or price > 100000:  # 价格范围
        return False
    return True
```

## 替代方案

### 1. 使用公开API
- **聚合数据**：https://www.juhe.cn
- **API Store**：https://www.apistore.cn
- **RapidAPI**：https://rapidapi.com

### 2. 数据采集服务
- **八爪鱼采集器**：提供可视化爬虫工具
- **Scrapy Cloud**：专业的爬虫托管服务

### 3. 购买数据服务
- 联系数据服务商购买价格数据
- 使用专业的数据API服务

## 总结

1. **优先使用官方API**：最安全、最稳定
2. **爬取仅供学习**：不要用于商业用途
3. **遵守法律法规**：尊重网站服务条款
4. **设置合理频率**：避免对服务器造成负担
5. **做好错误处理**：网站结构可能随时变化

## 免责声明

本代码仅供学习研究使用，使用者需自行承担使用风险。作者不对因使用本代码而产生的任何法律后果负责。

