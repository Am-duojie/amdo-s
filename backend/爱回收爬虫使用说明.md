# 爱回收爬虫使用说明

## ⚠️ 重要警告

**本爬虫仅供学习研究使用，请勿用于商业用途！**

### 法律风险
1. **违反服务条款**：爱回收网站的服务条款可能禁止爬取
2. **可能违法**：未经授权爬取可能违反相关法律
3. **IP封禁**：频繁爬取可能导致IP被封禁
4. **法律诉讼**：可能面临法律诉讼风险

### 使用建议
- 控制爬取频率，设置合理的延迟时间（建议2秒以上）
- 不要大规模爬取，仅用于学习研究
- 尊重网站的robots.txt
- 优先考虑使用官方API接口

## 功能特性

本爬虫支持以下功能：

1. **多分类爬取**：支持手机、电脑、平板、手表、耳机等多种商品分类
2. **商品列表爬取**：爬取商品标题、价格、图片等基础信息
3. **详情页爬取**：可选的详情页数据爬取，包括：
   - 商品详细描述
   - 规格参数
   - 质检报告
   - 详情图片
4. **数据导出**：自动保存为JSON格式

## 安装依赖

确保已安装以下依赖：

```bash
pip install playwright beautifulsoup4
playwright install chromium
```

## 使用方法

### 基本用法

```bash
# 爬取默认分类（手机、电脑、平板、手表、耳机），每个分类50条
python manage.py crawl_aihuishou

# 指定分类和数量
python manage.py crawl_aihuishou --categories "手机,平板" --per-category 30

# 爬取详情页数据（包括质检报告）
python manage.py crawl_aihuishou --detail

# 指定输出文件
python manage.py crawl_aihuishou --out "data/my_data.json"

# 调试模式（显示浏览器窗口）
python manage.py crawl_aihuishou --headful
```

### 参数说明

| 参数 | 说明 | 默认值 |
|------|------|--------|
| `--categories` | 要爬取的商品分类，用逗号分隔 | "手机,电脑,平板,手表,耳机" |
| `--per-category` | 每个分类爬取的商品数量 | 50 |
| `--out` | 输出JSON文件路径 | "backend/data/aihuishou_dataset.json" |
| `--delay` | 请求间隔（秒），建议2秒以上 | 2.0 |
| `--headful` | 显示浏览器窗口（调试用） | False |
| `--detail` | 是否爬取详情页数据 | False |

### 示例命令

```bash
# 爬取手机和电脑，每个分类100条，包含详情页数据
python manage.py crawl_aihuishou \
    --categories "手机,电脑" \
    --per-category 100 \
    --detail \
    --delay 3.0 \
    --out "backend/data/aihuishou_phones_laptops.json"

# 快速测试（少量数据，显示浏览器）
python manage.py crawl_aihuishou \
    --categories "手机" \
    --per-category 5 \
    --headful \
    --detail
```

## 输出数据格式

爬取的数据会保存为JSON格式，每个商品包含以下字段：

```json
{
  "title": "商品标题",
  "price": 价格（数字）,
  "original_price": 原价（数字，可选）,
  "category": "商品分类",
  "platform": "爱回收",
  "url": "商品链接",
  "images": ["图片URL1", "图片URL2"],
  "description": "商品描述",
  "condition": "商品成色（new/like_new/good/fair/poor）",
  "source": "数据来源",
  "quality_report": {
    "外观": "良好",
    "功能": "正常",
    "电池": "90%"
  },
  "specifications": {
    "品牌": "苹果",
    "型号": "iPhone 15 Pro",
    "存储": "256GB"
  },
  "detail_images": ["详情图片URL1", "详情图片URL2"]
}
```

## 注意事项

1. **爬取频率**：
   - 建议设置 `--delay` 至少2秒，避免过于频繁的请求
   - 大规模爬取时建议使用代理IP

2. **网站结构变化**：
   - 网站结构可能随时变化，如果爬取失败，可能需要更新选择器
   - 代码中已包含多种备用选择器，提高成功率

3. **详情页爬取**：
   - 使用 `--detail` 参数会显著增加爬取时间
   - 建议先测试少量数据，确认能正常爬取后再大规模使用

4. **数据准确性**：
   - 爬取的数据仅供参考，实际价格和库存可能随时变化
   - 建议定期更新数据

5. **错误处理**：
   - 如果爬取失败，会自动使用模拟数据填充
   - 检查输出日志了解爬取情况

## 故障排查

### 问题1：Playwright未安装

**错误信息**：`未安装 playwright，将使用模拟数据生成。`

**解决方法**：
```bash
pip install playwright
playwright install chromium
```

### 问题2：爬取失败或数据为空

**可能原因**：
- 网站结构已变化
- 网络连接问题
- IP被封禁

**解决方法**：
1. 使用 `--headful` 参数查看浏览器行为
2. 检查网络连接
3. 增加 `--delay` 延迟时间
4. 检查网站是否可正常访问

### 问题3：详情页爬取失败

**可能原因**：
- 详情页需要登录
- 详情页结构不同
- 链接无效

**解决方法**：
1. 检查商品链接是否有效
2. 使用 `--headful` 查看详情页加载情况
3. 可能需要更新选择器

## 技术实现

### 爬取流程

1. **初始化浏览器**：使用Playwright启动Chromium浏览器
2. **访问分类页面**：根据分类构建URL并访问
3. **提取商品列表**：从页面中提取商品卡片元素
4. **提取商品信息**：从每个商品卡片中提取标题、价格、图片等
5. **爬取详情页**（可选）：访问商品详情页提取详细信息
6. **保存数据**：将所有数据保存为JSON文件

### 关键技术

- **Playwright**：用于模拟浏览器访问动态网页
- **BeautifulSoup**：用于HTML解析（备用方案）
- **正则表达式**：用于提取价格、规格等信息
- **多选择器策略**：使用多种CSS选择器提高成功率

## 后续改进建议

1. **API接口**：如果发现爱回收的API接口，优先使用API
2. **数据清洗**：添加数据清洗和验证逻辑
3. **增量更新**：支持增量更新，只爬取新商品
4. **数据库存储**：支持直接保存到数据库
5. **并发控制**：支持多线程/异步爬取（需谨慎控制频率）

## 相关文件

- 爬虫命令：`backend/app/secondhand_app/management/commands/crawl_aihuishou.py`
- 数据输出目录：`backend/data/`
- 通用爬虫服务：`backend/app/secondhand_app/scraper_service.py`

